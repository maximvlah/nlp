{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e9487aacac19d12f92becf334e5d5faf807c71a056b8eebd57d5d8fc05554890"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tweeter Sentiment Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.python.client import device_lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the pre-processing parameters\n",
    "CLEAN = False\n",
    "EXTRACT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  sentiment                                               text\n",
       "0  Negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1  Negative  is upset that he can't update his Facebook by ...\n",
       "2  Negative  @Kenichan I dived many times for the ball. Man...\n",
       "3  Negative    my whole body feels itchy and like its on fire \n",
       "4  Negative  @nationwideclass no, it's not behaving at all...."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Negative</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Negative</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Negative</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Negative</td>\n      <td>my whole body feels itchy and like its on fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Negative</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#load data\n",
    "df = pd.read_csv('data/tweets.csv', header=None)\n",
    "#select important columns\n",
    "df = df[[0,5]]\n",
    "df.columns = ['sentiment','text']\n",
    "df['sentiment'] = df['sentiment'].replace([0, 4],['Negative','Positive'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "# df = df[:10000]\n",
    "# df.sentiment.value_counts()"
   ]
  },
  {
   "source": [
    "## Text Pre-Processing\n",
    "\n",
    "1. Remove links \n",
    "2. Remove mentions\n",
    "3. Remove punctuation\n",
    "4. Remove stopwords\n",
    "5. Lemmatize\n",
    "6. Stemming?\n",
    "7. Lowercase\n",
    "8. Strip whitespaces"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords with spacy\n",
    "def remove_stopwords(nlp, text):\n",
    "    #tokenize\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Create list of word tokens\n",
    "    token_list = []\n",
    "    for token in doc:\n",
    "        token_list.append(token.text)\n",
    "\n",
    "    # Create list of word tokens after removing stopwords\n",
    "    filtered_sentence = [] \n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_sentence.append(word) \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "# lemmatize tweet with spacy\n",
    "def lemmatize(nlp,text):\n",
    "\n",
    "    #tokenize\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemmatized = []\n",
    "    for token in doc:\n",
    "        # print(token, token.lemma, token.lemma_)\n",
    "        lemmatized.append(token.lemma_)\n",
    "\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "#Clean tweet\n",
    "def clean_tweet(nlp, tweet):\n",
    "    \n",
    "    clean = tweet\n",
    "    #remove links\n",
    "    clean = re.sub(r\"http\\S+\", \"\", clean)\n",
    "    #remove mentions\n",
    "    clean = re.sub(r\"@\\S+\", \"\", clean)\n",
    "    #remove punctuation\n",
    "    clean = clean.translate(str.maketrans('', '', string.punctuation)) #https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "    #remove stopwords\n",
    "    clean = remove_stopwords(nlp, clean)\n",
    "    #lemmatizing\n",
    "    clean = lemmatize(nlp, clean)\n",
    "    #strip whitespaces\n",
    "    clean = clean.strip()\n",
    "    #lowercase\n",
    "    clean = clean.lower()\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Process\n",
    "if CLEAN:\n",
    "    #Load spacy model -> needed for stopword removal and lemmatizing\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    #Enable progress tracking\n",
    "    tqdm.pandas()\n",
    "    #Run pre-processing on the whole dataset\n",
    "    df['clean'] = df.text.progress_apply(lambda x: clean_tweet(nlp,x))\n",
    "    #Save pre-processed data\n",
    "    df.to_csv('data/cleaned.csv')\n",
    "# else load the already pre-processed dataset\n",
    "else:\n",
    "    df = pd.read_csv('data/cleaned.csv', index_col=0)"
   ]
  },
  {
   "source": [
    "## Build Word Frequences for Each Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build frequency for a single class\n",
    "def build_freq(df,text_col):\n",
    "    #initiate counter\n",
    "    freq = Counter()\n",
    "    df[text_col].str.lower().str.split().apply(freq.update)\n",
    "    freq = dict(freq)\n",
    "    #sort the dictionary\n",
    "    freq = dict(sorted(freq.items(), key=lambda item: item[1], reverse=True)) #https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "\n",
    "    return freq\n",
    "\n",
    "#Build frequencies for each target class\n",
    "def multiclass_freqs(df,target_col,text_col):\n",
    "    #inititate frequency list\n",
    "    freq_list = []\n",
    "    #loop over unique classes\n",
    "    for c in df[target_col].unique():\n",
    "        #build frequency for the \"c\" class\n",
    "        freq = build_freq(df.loc[df[target_col] == c], text_col)\n",
    "        #append to the list\n",
    "        freq_list.append(freq)\n",
    "\n",
    "    return freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Positive    50058\n",
       "Negative    49942\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "#Sample less tweets to run the tests as it will take ages to pre-process who;e 1.6 million tweets\n",
    "SAMPLE_SIZE = 100000\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df = df[:SAMPLE_SIZE]\n",
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get frequencies for all columns\n",
    "freqs = multiclass_freqs(df,'sentiment','clean')\n",
    "\n",
    "# # positive frequency\n",
    "# pos_freq = build_freq(df.loc[df.sentiment == 'Positive'], 'clean')\n",
    "# # negative frequency \n",
    "# neg_freq = build_freq(df.loc[df.sentiment == 'Negative'], 'clean')"
   ]
  },
  {
   "source": [
    "## Feature Extraction with Frequencies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet,freq_list):\n",
    "    #split the tweet into words\n",
    "    tweet_words = tweet.split(' ')\n",
    "    #inititate the feature, bias = 1\n",
    "    feature = [1]\n",
    "\n",
    "    # loop over the given frequencies\n",
    "    for freq in freq_list:\n",
    "        #inititate frequency feature\n",
    "        f = 0\n",
    "        for word in tweet_words:\n",
    "            #if word is present in the freq dictionary\n",
    "            freq_words = list(freq.keys())\n",
    "            #sum the frequencies of each word in the tweet\n",
    "            if word in freq_words:\n",
    "                #add its frequency to the feature\n",
    "                f += freq[word]\n",
    "        feature.append(f)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXTRACT:\n",
    "    #Enable progress tracking\n",
    "    tqdm.pandas()\n",
    "    #Extract features on the whole dataset\n",
    "    features = df.clean.progress_apply(lambda tweet: extract_features(tweet,freqs))\n",
    "    df['features'] = features\n",
    "    df.to_csv('cleaned_with_features.csv')\n",
    "else:\n",
    "    df = pd.read_csv('data/cleaned_with_features.csv', index_col=0)\n",
    "    #transform features from string to list\n",
    "    df.features = df.features.apply(lambda x: ast.literal_eval(x))\n",
    "    features = df.features"
   ]
  },
  {
   "source": [
    "## Prepare Data for Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80000, 10000, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "#transform feature vector into a numpy array\n",
    "X = np.array([np.array(features[i]) for i in range(len(features))])\n",
    "#label encoding\n",
    "y = np.array(df.sentiment.astype('category').cat.codes)\n",
    "#split into train/test, train size 80k\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.2, random_state = 42)\n",
    "#split test set into val and test, each 10k records\n",
    "test_X, val_X, test_y, val_y = train_test_split(test_X,test_y, test_size=0.5, random_state = 42)\n",
    "#print lengths of the datasets\n",
    "len(train_X), len(val_X), len(test_X)"
   ]
  },
  {
   "source": [
    "## Train Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 0.7027\nPrecision: 0.6764452113891286\nRecall: 0.7811877241929055\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "y_pred = model.predict(test_X)\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(test_y, y_pred))\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(test_y, y_pred))"
   ]
  },
  {
   "source": [
    "### Support Vector Machine"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Create a svm Classifier\n",
    "# clf = svm.SVC(kernel='linear', verbose=1) # Linear Kernel\n",
    "\n",
    "# #Train the model using the training sets\n",
    "# clf.fit(train_X, train_y)\n",
    "\n",
    "# #Predict the response for test dataset\n",
    "# y_pred = clf.predict(test_X)\n",
    "\n",
    "# #Make predictions\n",
    "# y_pred = model.predict(test_X)\n",
    "# # Model Accuracy: how often is the classifier correct?\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "# # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "# print(\"Precision:\",metrics.precision_score(test_y, y_pred))\n",
    "# # Model Recall: what percentage of positive tuples are labelled as such?\n",
    "# print(\"Recall:\",metrics.recall_score(test_y, y_pred))"
   ]
  },
  {
   "source": [
    "### Artificial Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss history\n",
    "def plot_loss_history(history):\n",
    "    loss_history = pd.DataFrame(history.history)\n",
    "    loss_history['epoch'] = loss_history.index.values\n",
    "    fig = px.line(loss_history, x = 'epoch', y = ['loss','val_loss'], title = 'Train vs Validation Loss During Training')\n",
    "    fig.show()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 27.0111 - accuracy: 0.5689 - val_loss: 1.1400 - val_accuracy: 0.5873\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.2081 - accuracy: 0.6225 - val_loss: 1.3918 - val_accuracy: 0.5588\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0914 - accuracy: 0.6331 - val_loss: 1.5663 - val_accuracy: 0.5230\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 1s 1ms/step - loss: 1.0621 - accuracy: 0.6355 - val_loss: 1.1403 - val_accuracy: 0.6473\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1379 - accuracy: 0.6326 - val_loss: 0.8959 - val_accuracy: 0.6253\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0599 - accuracy: 0.6368 - val_loss: 0.8974 - val_accuracy: 0.6868\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0945 - accuracy: 0.6371 - val_loss: 1.2321 - val_accuracy: 0.7126\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1518 - accuracy: 0.6334 - val_loss: 0.7869 - val_accuracy: 0.7111\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0978 - accuracy: 0.6358 - val_loss: 1.6742 - val_accuracy: 0.6897\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.1483 - accuracy: 0.6321 - val_loss: 1.0620 - val_accuracy: 0.5916\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 1.1409 - accuracy: 0.6329 - val_loss: 1.4293 - val_accuracy: 0.5363\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9943 - accuracy: 0.6409 - val_loss: 2.3588 - val_accuracy: 0.6226\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.2202 - accuracy: 0.6356 - val_loss: 1.3527 - val_accuracy: 0.6528\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.1279 - accuracy: 0.6360 - val_loss: 0.7923 - val_accuracy: 0.7091\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 1.1439 - accuracy: 0.6340 - val_loss: 0.6224 - val_accuracy: 0.6557\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1097 - accuracy: 0.6326 - val_loss: 2.5532 - val_accuracy: 0.5355\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9164 - accuracy: 0.6401 - val_loss: 0.6540 - val_accuracy: 0.6780\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1184 - accuracy: 0.6327 - val_loss: 1.5854 - val_accuracy: 0.6595\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0714 - accuracy: 0.6391 - val_loss: 0.8218 - val_accuracy: 0.6572\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0584 - accuracy: 0.6354 - val_loss: 0.8412 - val_accuracy: 0.6393\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0909 - accuracy: 0.6330 - val_loss: 0.9064 - val_accuracy: 0.5818\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0227 - accuracy: 0.6377 - val_loss: 1.2904 - val_accuracy: 0.6525\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0071 - accuracy: 0.6380 - val_loss: 0.8780 - val_accuracy: 0.6093\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.1535 - accuracy: 0.6333 - val_loss: 1.8009 - val_accuracy: 0.6454\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9586 - accuracy: 0.6368 - val_loss: 0.6439 - val_accuracy: 0.7057\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0806 - accuracy: 0.6336 - val_loss: 0.7284 - val_accuracy: 0.6390\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9401 - accuracy: 0.6377 - val_loss: 0.7454 - val_accuracy: 0.6497\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9514 - accuracy: 0.6404 - val_loss: 0.6511 - val_accuracy: 0.6492\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.0560 - accuracy: 0.6369 - val_loss: 0.9725 - val_accuracy: 0.5933\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9600 - accuracy: 0.6408 - val_loss: 1.1553 - val_accuracy: 0.5808\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.0117 - accuracy: 0.6381 - val_loss: 0.8637 - val_accuracy: 0.6838\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.1295 - accuracy: 0.6350 - val_loss: 0.8224 - val_accuracy: 0.6991\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 1.0340 - accuracy: 0.6355 - val_loss: 0.9771 - val_accuracy: 0.6569\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9625 - accuracy: 0.6375 - val_loss: 0.6400 - val_accuracy: 0.6994\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.9872 - accuracy: 0.6384 - val_loss: 1.5791 - val_accuracy: 0.6583\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9784 - accuracy: 0.6396 - val_loss: 0.6787 - val_accuracy: 0.6488\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9178 - accuracy: 0.6386 - val_loss: 1.1152 - val_accuracy: 0.5888\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 1.0006 - accuracy: 0.6383 - val_loss: 1.1098 - val_accuracy: 0.5761\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.8815 - accuracy: 0.6436 - val_loss: 0.6929 - val_accuracy: 0.7138\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.9312 - accuracy: 0.6375 - val_loss: 0.7618 - val_accuracy: 0.7126\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8873 - accuracy: 0.6424 - val_loss: 0.9849 - val_accuracy: 0.5765\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8752 - accuracy: 0.6447 - val_loss: 0.5979 - val_accuracy: 0.7121\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9262 - accuracy: 0.6396 - val_loss: 0.9163 - val_accuracy: 0.5456\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9624 - accuracy: 0.6414 - val_loss: 0.6335 - val_accuracy: 0.7092\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.8776 - accuracy: 0.6455 - val_loss: 1.0837 - val_accuracy: 0.5639\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.9195 - accuracy: 0.6466 - val_loss: 0.6062 - val_accuracy: 0.6894\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8803 - accuracy: 0.6500 - val_loss: 0.8069 - val_accuracy: 0.6891\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.9230 - accuracy: 0.6436 - val_loss: 0.9129 - val_accuracy: 0.6855\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 2s 2ms/step - loss: 0.8842 - accuracy: 0.6506 - val_loss: 0.7825 - val_accuracy: 0.7076\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 1s 2ms/step - loss: 0.8794 - accuracy: 0.6463 - val_loss: 1.0451 - val_accuracy: 0.5723\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 128\n",
    "VERBOSITY = 1\n",
    "input_dim = train_X.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(8, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "# model.summary()\n",
    "\n",
    "history = model.fit(train_X, train_y,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=VERBOSITY,\n",
    "                    validation_data=(val_X, val_y),\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy: 0.5708\n",
      "Test Accuracy:  0.5763\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(train_X, train_y, verbose=False)\n",
    "print(\"Train Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(test_X, test_y, verbose=False)\n",
    "print(\"Test Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=loss<br>epoch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "loss",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "xaxis": "x",
         "y": [
          50.4241828918457,
          2.913966655731201,
          2.8957011699676514,
          2.663508892059326,
          2.564347505569458,
          2.781493663787842,
          2.814180612564087,
          2.261082172393799,
          2.4883670806884766,
          2.531885862350464,
          2.557068347930908,
          2.7477102279663086,
          2.338407516479492,
          2.869163751602173,
          2.3170976638793945,
          2.2904531955718994,
          2.5980584621429443,
          2.5743722915649414,
          2.6369471549987793,
          2.309589147567749,
          2.5128087997436523,
          2.1201999187469482,
          2.1279826164245605,
          2.230252742767334,
          2.142075777053833,
          2.3081514835357666,
          2.2307381629943848,
          2.3313231468200684,
          2.30826473236084,
          2.247878313064575,
          2.2342545986175537,
          2.10752272605896,
          2.222888469696045,
          2.346250534057617,
          2.388798236846924,
          2.025118350982666,
          2.6229817867279053,
          2.3843460083007812,
          2.4935390949249268,
          2.437103748321533,
          2.607257843017578,
          2.264785051345825,
          2.058295965194702,
          1.8427156209945679,
          2.39086651802063,
          1.9611921310424805,
          2.449925661087036,
          2.559072494506836,
          2.2610204219818115,
          2.0819554328918457
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=val_loss<br>epoch=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val_loss",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "mode": "lines",
         "name": "val_loss",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49
         ],
         "xaxis": "x",
         "y": [
          4.340445041656494,
          1.3952897787094116,
          5.9264421463012695,
          3.30267333984375,
          4.931434154510498,
          1.1861504316329956,
          1.219740390777588,
          1.2435975074768066,
          4.872570991516113,
          1.89194917678833,
          3.5889527797698975,
          2.34728741645813,
          6.262180805206299,
          3.2903003692626953,
          1.1589806079864502,
          1.2450928688049316,
          1.5686722993850708,
          2.41591477394104,
          0.7747278809547424,
          3.2557337284088135,
          4.851601600646973,
          1.3990767002105713,
          2.5830018520355225,
          0.9703035354614258,
          5.287987232208252,
          2.9279589653015137,
          3.5374772548675537,
          3.9070050716400146,
          1.2528772354125977,
          2.0449166297912598,
          2.45603609085083,
          0.8157360553741455,
          1.3528871536254883,
          1.69559907913208,
          3.455941915512085,
          1.5319609642028809,
          2.4620728492736816,
          1.7904841899871826,
          1.729202151298523,
          0.6954211592674255,
          0.9904217720031738,
          2.822411060333252,
          2.0242362022399902,
          2.0736165046691895,
          1.6568212509155273,
          3.3264966011047363,
          4.128177642822266,
          3.634153127670288,
          1.1426141262054443,
          1.1868261098861694
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Train vs Validation Loss During Training"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "value"
         }
        }
       }
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy  epoch\n",
       "0   50.424183  0.579862  4.340445        0.5116      0\n",
       "1    2.913967  0.598013  1.395290        0.6171      1\n",
       "2    2.895701  0.604100  5.926442        0.5288      2\n",
       "3    2.663509  0.614575  3.302673        0.5532      3\n",
       "4    2.564348  0.620162  4.931434        0.5328      4\n",
       "5    2.781494  0.623850  1.186150        0.6642      5\n",
       "6    2.814181  0.624950  1.219740        0.6133      6\n",
       "7    2.261082  0.627600  1.243598        0.6928      7\n",
       "8    2.488367  0.630450  4.872571        0.5404      8\n",
       "9    2.531886  0.629138  1.891949        0.5481      9\n",
       "10   2.557068  0.628225  3.588953        0.7067     10\n",
       "11   2.747710  0.627375  2.347287        0.5719     11\n",
       "12   2.338408  0.630800  6.262181        0.5135     12\n",
       "13   2.869164  0.626113  3.290300        0.5761     13\n",
       "14   2.317098  0.632338  1.158981        0.7093     14\n",
       "15   2.290453  0.631863  1.245093        0.7084     15\n",
       "16   2.598058  0.630063  1.568672        0.7027     16\n",
       "17   2.574372  0.632675  2.415915        0.6538     17\n",
       "18   2.636947  0.628038  0.774728        0.6307     18\n",
       "19   2.309589  0.631925  3.255734        0.6036     19\n",
       "20   2.512809  0.631688  4.851602        0.6006     20\n",
       "21   2.120200  0.631688  1.399077        0.7044     21\n",
       "22   2.127983  0.633762  2.583002        0.7031     22\n",
       "23   2.230253  0.632625  0.970304        0.6550     23\n",
       "24   2.142076  0.632338  5.287987        0.5322     24\n",
       "25   2.308151  0.633712  2.927959        0.7031     25\n",
       "26   2.230738  0.631588  3.537477        0.5371     26\n",
       "27   2.331323  0.632075  3.907005        0.5354     27\n",
       "28   2.308265  0.629225  1.252877        0.6913     28\n",
       "29   2.247878  0.632900  2.044917        0.5448     29\n",
       "30   2.234255  0.632150  2.456036        0.6146     30\n",
       "31   2.107523  0.631562  0.815736        0.7046     31\n",
       "32   2.222888  0.634850  1.352887        0.6561     32\n",
       "33   2.346251  0.630663  1.695599        0.5474     33\n",
       "34   2.388798  0.629587  3.455942        0.5509     34\n",
       "35   2.025118  0.633250  1.531961        0.6343     35\n",
       "36   2.622982  0.629663  2.462073        0.5483     36\n",
       "37   2.384346  0.631662  1.790484        0.6797     37\n",
       "38   2.493539  0.628513  1.729202        0.6265     38\n",
       "39   2.437104  0.631675  0.695421        0.6768     39\n",
       "40   2.607258  0.630313  0.990422        0.6354     40\n",
       "41   2.264785  0.631787  2.822411        0.5464     41\n",
       "42   2.058296  0.631187  2.024236        0.6337     42\n",
       "43   1.842716  0.632788  2.073617        0.5573     43\n",
       "44   2.390867  0.630838  1.656821        0.6816     44\n",
       "45   1.961192  0.629363  3.326497        0.6873     45\n",
       "46   2.449926  0.631938  4.128178        0.5448     46\n",
       "47   2.559072  0.630825  3.634153        0.5385     47\n",
       "48   2.261020  0.631150  1.142614        0.6250     48\n",
       "49   2.081955  0.629987  1.186826        0.6966     49"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>val_loss</th>\n      <th>val_accuracy</th>\n      <th>epoch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50.424183</td>\n      <td>0.579862</td>\n      <td>4.340445</td>\n      <td>0.5116</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.913967</td>\n      <td>0.598013</td>\n      <td>1.395290</td>\n      <td>0.6171</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.895701</td>\n      <td>0.604100</td>\n      <td>5.926442</td>\n      <td>0.5288</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.663509</td>\n      <td>0.614575</td>\n      <td>3.302673</td>\n      <td>0.5532</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.564348</td>\n      <td>0.620162</td>\n      <td>4.931434</td>\n      <td>0.5328</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.781494</td>\n      <td>0.623850</td>\n      <td>1.186150</td>\n      <td>0.6642</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2.814181</td>\n      <td>0.624950</td>\n      <td>1.219740</td>\n      <td>0.6133</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.261082</td>\n      <td>0.627600</td>\n      <td>1.243598</td>\n      <td>0.6928</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2.488367</td>\n      <td>0.630450</td>\n      <td>4.872571</td>\n      <td>0.5404</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2.531886</td>\n      <td>0.629138</td>\n      <td>1.891949</td>\n      <td>0.5481</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2.557068</td>\n      <td>0.628225</td>\n      <td>3.588953</td>\n      <td>0.7067</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2.747710</td>\n      <td>0.627375</td>\n      <td>2.347287</td>\n      <td>0.5719</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2.338408</td>\n      <td>0.630800</td>\n      <td>6.262181</td>\n      <td>0.5135</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2.869164</td>\n      <td>0.626113</td>\n      <td>3.290300</td>\n      <td>0.5761</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2.317098</td>\n      <td>0.632338</td>\n      <td>1.158981</td>\n      <td>0.7093</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2.290453</td>\n      <td>0.631863</td>\n      <td>1.245093</td>\n      <td>0.7084</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2.598058</td>\n      <td>0.630063</td>\n      <td>1.568672</td>\n      <td>0.7027</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2.574372</td>\n      <td>0.632675</td>\n      <td>2.415915</td>\n      <td>0.6538</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2.636947</td>\n      <td>0.628038</td>\n      <td>0.774728</td>\n      <td>0.6307</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2.309589</td>\n      <td>0.631925</td>\n      <td>3.255734</td>\n      <td>0.6036</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2.512809</td>\n      <td>0.631688</td>\n      <td>4.851602</td>\n      <td>0.6006</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2.120200</td>\n      <td>0.631688</td>\n      <td>1.399077</td>\n      <td>0.7044</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2.127983</td>\n      <td>0.633762</td>\n      <td>2.583002</td>\n      <td>0.7031</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>2.230253</td>\n      <td>0.632625</td>\n      <td>0.970304</td>\n      <td>0.6550</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>2.142076</td>\n      <td>0.632338</td>\n      <td>5.287987</td>\n      <td>0.5322</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2.308151</td>\n      <td>0.633712</td>\n      <td>2.927959</td>\n      <td>0.7031</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2.230738</td>\n      <td>0.631588</td>\n      <td>3.537477</td>\n      <td>0.5371</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2.331323</td>\n      <td>0.632075</td>\n      <td>3.907005</td>\n      <td>0.5354</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2.308265</td>\n      <td>0.629225</td>\n      <td>1.252877</td>\n      <td>0.6913</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>2.247878</td>\n      <td>0.632900</td>\n      <td>2.044917</td>\n      <td>0.5448</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2.234255</td>\n      <td>0.632150</td>\n      <td>2.456036</td>\n      <td>0.6146</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>2.107523</td>\n      <td>0.631562</td>\n      <td>0.815736</td>\n      <td>0.7046</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>2.222888</td>\n      <td>0.634850</td>\n      <td>1.352887</td>\n      <td>0.6561</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2.346251</td>\n      <td>0.630663</td>\n      <td>1.695599</td>\n      <td>0.5474</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>2.388798</td>\n      <td>0.629587</td>\n      <td>3.455942</td>\n      <td>0.5509</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>2.025118</td>\n      <td>0.633250</td>\n      <td>1.531961</td>\n      <td>0.6343</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>2.622982</td>\n      <td>0.629663</td>\n      <td>2.462073</td>\n      <td>0.5483</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>2.384346</td>\n      <td>0.631662</td>\n      <td>1.790484</td>\n      <td>0.6797</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>2.493539</td>\n      <td>0.628513</td>\n      <td>1.729202</td>\n      <td>0.6265</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2.437104</td>\n      <td>0.631675</td>\n      <td>0.695421</td>\n      <td>0.6768</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>2.607258</td>\n      <td>0.630313</td>\n      <td>0.990422</td>\n      <td>0.6354</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>2.264785</td>\n      <td>0.631787</td>\n      <td>2.822411</td>\n      <td>0.5464</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>2.058296</td>\n      <td>0.631187</td>\n      <td>2.024236</td>\n      <td>0.6337</td>\n      <td>42</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1.842716</td>\n      <td>0.632788</td>\n      <td>2.073617</td>\n      <td>0.5573</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>2.390867</td>\n      <td>0.630838</td>\n      <td>1.656821</td>\n      <td>0.6816</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1.961192</td>\n      <td>0.629363</td>\n      <td>3.326497</td>\n      <td>0.6873</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>2.449926</td>\n      <td>0.631938</td>\n      <td>4.128178</td>\n      <td>0.5448</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>2.559072</td>\n      <td>0.630825</td>\n      <td>3.634153</td>\n      <td>0.5385</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>2.261020</td>\n      <td>0.631150</td>\n      <td>1.142614</td>\n      <td>0.6250</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>2.081955</td>\n      <td>0.629987</td>\n      <td>1.186826</td>\n      <td>0.6966</td>\n      <td>49</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}